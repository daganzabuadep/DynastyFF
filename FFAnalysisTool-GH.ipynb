{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip -q install numpy\n",
    "import os.path\n",
    "from os import path\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#Webscraping\n",
    "import requests\n",
    "#for stats\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Socring settings\n",
    "yard_pass=0.04\n",
    "td_pass=6\n",
    "fd_pass=0.25\n",
    "twoPC= 2.0\n",
    "intcp = -4\n",
    "yard_rush = 0.1\n",
    "td_rush = 6\n",
    "fd_rush =1\n",
    "att_rush = 0.25\n",
    "yard_rec = 0.1\n",
    "td_rec = 6\n",
    "fd_rec = 1\n",
    "fmble = -2\n",
    "sack = 0\n",
    "rec_te = 1.5\n",
    "rec = 1\n",
    "Yds100Bonus = 0.5\n",
    "Yds200Bonus = 1\n",
    "Yds300Bonus = 2\n",
    "Pass300Bonus = 1\n",
    "Pass400Bonus = 2\n",
    "PassCmpBonus = 1\n",
    "Compl25 = 1\n",
    "Carry20Bonus = 1\n",
    "start_year = 2000\n",
    "end_year = 2019\n",
    "bonus_toggle = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate fantasy points\n",
    "search_values = ['te','TE'] #filter TEs\n",
    "def calcPassFP(row):\n",
    "    pass_FP = yard_pass * float(row['PassYds']) + td_pass * float(row['PassTD'])+ fd_pass * float(row['Pass1D'])+ \\\n",
    "              intcp * float(row['Int']) + sack * float(row['Sk'])  \n",
    "    #Using a CDF to calculate the likelihood of having bonuses..\n",
    "    # cdf(x > val)\n",
    "    #print (1 - norm.cdf(300,200, 100))\n",
    "    bonus = bonus_toggle * abs(Pass300Bonus * (1-norm.cdf(300,float(row['PassY/G']),75)) * float(row['G']) + \\\n",
    "            Pass400Bonus * (1-norm.cdf(400,float(row['PassY/G']),75)) * float(row['G']) + \\\n",
    "            Compl25 * (1- norm.cdf(25,float(row['Cmp'])/float(row['G']),15) * float(row['G'])))\n",
    "    #print(bonus)\n",
    "    pass_FP = round(pass_FP+bonus, 2)\n",
    "    return pass_FP\n",
    "\n",
    "def calcPassFP_PG(row):\n",
    "    return float(round(row['Passing FP']/(float(row['G'])),2))\n",
    "\n",
    "#Calculate fantasy points for rushers\n",
    "def calcRushFP(row):\n",
    "    rush_FP = yard_rush * float(row['RushYds']) + td_rush * float(row['RushTD'])+ fd_rush * float(row['Rush1D']) + \\\n",
    "              fmble * float(row['RushFmb']) + att_rush * float(row['RushAtt'])\n",
    "    #Using a CDF to calculate the likelihood of having bonuses..\n",
    "    # cdf(x > val)\n",
    "    #print (1 - norm.cdf(300,200, 100))\n",
    "    #LEFT OFF HERE\n",
    "    bonus = bonus_toggle *abs(Yds100Bonus * (1- norm.cdf(100,float(row['RushY/G']),20)) * float(row['G']) + \\\n",
    "            Yds200Bonus * (1- norm.cdf(200,float(row['RushY/G']),20)) * float(row['G']) + \\\n",
    "            Yds300Bonus *  (1- norm.cdf(300,float(row['RushY/G']),20)) * float(row['G']) + \\\n",
    "            Carry20Bonus *(1- norm.cdf(20,float(row['RushAtt']),5)) * float(row['G']))\n",
    "    rush_FP = round(bonus+rush_FP,2)\n",
    "    #print(rush_FP)\n",
    "    #print(int(row['G']))\n",
    "    return rush_FP\n",
    "\n",
    "def calcRushFP_PG(row):\n",
    "    PPG = float((float(row['Rushing FP']))/(int(row['G'])))\n",
    "    PPG = round(PPG,2)\n",
    "    #print(PPG)\n",
    "    return PPG\n",
    "\n",
    "#Calculate fantasy points for receivers\n",
    "def calcRecFP(row):\n",
    "    if (\"TE\" in str(row['Pos']).upper()):\n",
    "        row['Pos'] = 'TE'\n",
    "        rec_FP = yard_rec * float(row['RecYds']) + td_rec * float(row['RecTD'])+ fd_rec * float(row['Rec1D']) + \\\n",
    "                 rec_te * float(row['Rec'])\n",
    "    else:\n",
    "        rec_FP = yard_rec * float(row['RecYds']) + td_rec * float(row['RecTD'])+ fd_rec * float(row['Rec1D']) + \\\n",
    "                 rec * float(row['Rec'])\n",
    "    #Using a CDF to calculate the likelihood of having bonuses..\n",
    "    # cdf(x > val)\n",
    "    #print (1 - norm.cdf(300,200, 100))\n",
    "    #LEFT OFF HERE\n",
    "    bonus = bonus_toggle *abs(Yds100Bonus * (1 - norm.cdf(100,float(row['RecY/G']),20)) * float(row['G']) + \\\n",
    "            Yds200Bonus * (1 - norm.cdf(200,float(row['RecY/G']),20)) * float(row['G']) + \\\n",
    "            Yds300Bonus *  (1 - norm.cdf(300,float(row['RecY/G']),20)) * float(row['G']))\n",
    "    rec_FP = round(bonus+rec_FP,2)\n",
    "    #print(rec_FP)\n",
    "    #print(int(row['G']))\n",
    "    return rec_FP\n",
    "\n",
    "def calcRecFP_PG(row):\n",
    "    PPG = float(row['Receiving FP'])/(float(row['G']))\n",
    "    PPG = round(PPG,2)\n",
    "    #print(PPG)\n",
    "    return PPG\n",
    "#total points\n",
    "def calcTotalFP(row):\n",
    "    totalFP =  round((float(row['Rushing FP']) +  float(row['Passing FP']) + float(row['Receiving FP'])),2)\n",
    "    #print(totalFP)\n",
    "    return totalFP\n",
    "\n",
    "def calcTotalFP_PG(row):\n",
    "    PPG = float(row['Total FP'])/(float(row['G']))\n",
    "    PPG = round(PPG,2)\n",
    "    #print(PPG)\n",
    "    return PPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to download tables from pro football ref and save under the folder location with correct years\n",
    "#Set save and download location\n",
    "folder = \"\" #Select preferred save location e.g /home/data/UsrBot/GoLions\n",
    "url = 'https://www.pro-football-reference.com/years/'\n",
    "year_range= np.arange(start_year,end_year,1)\n",
    "category='/passing' #change to receiving or rushing\n",
    "passing_dfs = []\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "for year in range(start_year,end_year+1): #loop over all years to consider, year is f.e start_year\n",
    "    \n",
    "    full_link = url + str(year) + str(category) + '.htm'\n",
    "    #print(full_link)\n",
    "    file_name = Path(folder+str(category)+str(year)+'.csv')    \n",
    "    \n",
    "    if not file_name.is_file():\n",
    "        #Downloads all tables from the provided links as seperate .csv files.   \n",
    "        html = requests.get(full_link).content\n",
    "        df_list = pd.read_html(html)\n",
    "        df = df_list[-1]\n",
    "        print('Trying to save data from '+ full_link)\n",
    "        if not (df.empty): #dataframe isn't empy, convert to csv and print\n",
    "            df.to_csv(file_name)\n",
    "            print('Sucessfully saved as .csv')\n",
    "    else: \n",
    "        print('File:' + str(file_name)+ ' already exists.')\n",
    "        \n",
    "    #fill array to hold each panda dataframe \n",
    "    if (file_name.is_file()):\n",
    "        passing_dfs.append(pd.read_csv(file_name,header=0)) #add dfs \n",
    "       # print(\"Data from \"+ str(file_name) +\"has been loaded into dataframe number \"+ str(year-start_year))\n",
    "# dfs[0] holds the start year, dfs[year-start_year] holds the last year selected => end_year\n",
    "\n",
    "    passing_dfs[year-start_year] = passing_dfs[year-start_year].drop(passing_dfs[year-start_year].columns[0],axis=1) #remove first column\n",
    "    passing_dfs[year-start_year] = passing_dfs[year-start_year].rename(columns={\"Yds.1\": \"Yds_Sk\",\"Yds\":\"PassYds\",\"TD\":\"PassTD\",\"1D\":\"Pass1D\",\"Y/G\":\"PassY/G\",\"Att\":\"PassAtt\"})\n",
    "    passing_dfs[year-start_year] = passing_dfs[year-start_year][passing_dfs[year-start_year].GS.apply(lambda x: x.isnumeric())] #drops all rows w/o number entries\n",
    "    #Add & sort FPPG\n",
    "    FP_Passing = passing_dfs[year-start_year].apply(calcPassFP,axis=1)\n",
    "    passing_dfs[year-start_year]['Passing FP'] = FP_Passing\n",
    "    FP_Passing_PG = passing_dfs[year-start_year].apply(calcPassFP_PG,axis=1)\n",
    "    passing_dfs[year-start_year]['Passing FPPG'] = FP_Passing_PG\n",
    "    #passing_dfs[year-start_year] = passing_dfs[year-start_year].drop(passing_dfs[year-start_year].columns[0],axis=1) #remove first column\n",
    "    passing_dfs[year-start_year] = passing_dfs[year-start_year].sort_values(by=['Passing FP'],ascending=False) #sort by most FP\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to download tables from pro football ref and save under the folder location with correct years\n",
    "#Set save and download location\n",
    "folder = \"\"\n",
    "url = 'https://www.pro-football-reference.com/years/'\n",
    "year_range= np.arange(start_year,end_year,1)\n",
    "category='/rushing' #change to receiving or rushing\n",
    "rushing_dfs = []\n",
    "\n",
    "for year in range(start_year,end_year+1): #loop over all years to consider\n",
    "    \n",
    "    full_link = url + str(year) + str(category) + '.htm'\n",
    "    #print(full_link)\n",
    "    file_name = Path(folder+str(category)+str(year)+'.csv')    \n",
    "    \n",
    "    if not file_name.is_file():\n",
    "        #Downloads all tables from the provided links as seperate .csv files.   \n",
    "        html = requests.get(full_link).content\n",
    "        df_list = pd.read_html(html)\n",
    "        df = df_list[-1]\n",
    "        print('Trying to save data from '+ full_link)\n",
    "        if not (df.empty): #dataframe isn't empy, convert to csv and print\n",
    "            df.to_csv(file_name)\n",
    "            print('Sucessfully saved as .csv')\n",
    "    else: \n",
    "        print('File:' + str(file_name)+ ' already exists.')\n",
    "        \n",
    "    #fill array to hold each panda dataframe \n",
    "    if (file_name.is_file()):\n",
    "        rushing_dfs.append(pd.read_csv(file_name,header=0)) #add dfs t\n",
    "       # print(\"Data from \"+ str(file_name) +\"has been loaded into dataframe number \"+ str(year-start_year))\n",
    "# dfs[0] holds the start year, dfs[year-start_year] holds the last year selected => end_year\n",
    "\n",
    "    #Code for removing double header in rushing\n",
    "    new_header = rushing_dfs[year-start_year].iloc[0] #grab the first row for the header\n",
    "    rushing_dfs[year-start_year] = rushing_dfs[year-start_year][1:] #take the data less the header row\n",
    "    rushing_dfs[year-start_year].columns = new_header #set the header row as the df header\n",
    "    rushing_dfs[year-start_year] = rushing_dfs[year-start_year][rushing_dfs[year-start_year].GS.apply(lambda x: x.isnumeric())] #drops all rows w/o number entries\n",
    "    rushing_dfs[year-start_year] = rushing_dfs[year-start_year].rename(columns={\"Yds\":\"RushYds\",\"TD\":\"RushTD\",\"1D\":\"Rush1D\",\"Fmb\":\"RushFmb\",\"Att\":\"RushAtt\",\"Y/G\":\"RushY/G\"})\n",
    "    \n",
    "    #Test rushing points\n",
    "    FP_Rushing = rushing_dfs[year-start_year].apply(calcRushFP,axis=1)\n",
    "    rushing_dfs[year-start_year]['Rushing FP'] = FP_Rushing\n",
    "    FP_Rushing_PG = rushing_dfs[year-start_year].apply(calcRushFP_PG,axis=1)\n",
    "    rushing_dfs[year-start_year]['Rushing FPPG'] = FP_Rushing_PG\n",
    "    #rushing_df = rushing_df.sort_values(by=['Rushing FP PG'],ascending=False) #sort by most FP\n",
    "    #rushing_df[1:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to download tables from pro football ref and save under the folder location with correct years\n",
    "#Set save and download location\n",
    "folder = \"/\" #Select preferred save location e.g /home/data/UsrBot/GoLions/ , keep / at the end!\n",
    "url = 'https://www.pro-football-reference.com/years/'\n",
    "year_range= np.arange(start_year,end_year,1)\n",
    "category='/receiving' #change to receiving or rushing\n",
    "receiving_dfs = []\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "for year in range(start_year,end_year+1): #loop over all years to consider, year is f.e start_year\n",
    "    \n",
    "    full_link = url + str(year) + str(category) + '.htm'\n",
    "    #print(full_link)\n",
    "    file_name = Path(folder+str(category)+str(year)+'.csv')    \n",
    "    \n",
    "    if not file_name.is_file():\n",
    "        #Downloads all tables from the provided links as seperate .csv files.   \n",
    "        html = requests.get(full_link).content\n",
    "        df_list = pd.read_html(html)\n",
    "        df = df_list[-1]\n",
    "        print('Trying to save data from '+ full_link)\n",
    "        if not (df.empty): #dataframe isn't empy, convert to csv and print\n",
    "            df.to_csv(file_name)\n",
    "            print('Sucessfully saved as .csv')\n",
    "    else: \n",
    "        print('File:' + str(file_name)+ ' already exists.')\n",
    "        \n",
    "    #fill array to hold each panda dataframe \n",
    "    if (file_name.is_file()):\n",
    "        receiving_dfs.append(pd.read_csv(file_name,header=0)) #add dfs \n",
    "        # print(\"Data from \"+ str(file_name) +\"has been loaded into dataframe number \"+ str(year-start_year))\n",
    "        # dfs[0] holds the start year, dfs[year-start_year] holds the last year selected => end_year\n",
    "\n",
    "    receiving_dfs[year-start_year] = receiving_dfs[year-start_year].drop(receiving_dfs[year-start_year].columns[0],axis=1) #remove first column\n",
    "    receiving_dfs[year-start_year] = receiving_dfs[year-start_year].rename(columns=\\\n",
    "                               {\"Yds\": \"RecYds\",\"TD\":\"RecTD\",\"1D\":\"Rec1D\",\"Fmb\":\"RecFmb\",\"Y/G\":\"RecY/G\"})\n",
    "    receiving_dfs[year-start_year] = receiving_dfs[year-start_year][receiving_dfs[year-start_year].GS.apply(lambda x: x.isnumeric())] #drops all rows w/o number entries\n",
    "    #Add & sort FPPG\n",
    "    FP_receiving = receiving_dfs[year-start_year].apply(calcRecFP,axis=1)\n",
    "    receiving_dfs[year-start_year]['Receiving FP'] = FP_receiving\n",
    "    FP_receiving_PG = receiving_dfs[year-start_year].apply(calcRecFP_PG,axis=1)\n",
    "    receiving_dfs[year-start_year]['Receiving FPPG'] = FP_receiving_PG\n",
    "    receiving_dfs[year-start_year] = receiving_dfs[year-start_year].sort_values(by=['Receiving FPPG'],ascending=False) #sort by most FP\n",
    "    #receiving_dfs[year-start_year][receiving_dfs[year-start_year]['Pos'].str.contains('|'.join(search_values ),na=False)] #show only TEs\n",
    "    #receiving_dfs[year-start_year][receiving_dfs[year-start_year]['Player'].str.contains(\"Travis\",na=False)] #show only KELCE\n",
    "    #receiving_dfs[year-start_year] = receiving_dfs[year-start_year].drop(['Rk'],axis=1) #remove first column\n",
    "    #receiving_dfs[year-start_year].sort_values(by=['Receiving FP'],ascending=False) #sort by most FP\n",
    "    #pd.set_option(\"display.max_rows\", None, \"dislay.max_columns\", None)\n",
    "    #receiving_dfs[year-start_year][receiving_df['Player'].str.contains(\"Hoop\",na=False)] #show only KELCE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dfs = []\n",
    "total_dfs = []\n",
    "QB_dfs = []\n",
    "WR_dfs = []\n",
    "RB_dfs = []\n",
    "TE_dfs = []\n",
    "newDF = pd.DataFrame() #creates a new dataframe that's empty\n",
    "\n",
    "\n",
    "for year in range(start_year,end_year+1): #loop over all years to consider, year is f.e start_year\n",
    "    merged_dfs.append(pd.read_csv(file_name,header=0)) #add dfs\n",
    "    merged_dfs[year-start_year] = rushing_dfs[year-start_year][['Player','G','Tm','Age','Pos','RushAtt','RushYds','RushTD','Rush1D','Rushing FP', 'Rushing FPPG']].merge( \\\n",
    "            receiving_dfs[year-start_year][['Player','G','Tm','Age','Pos','Rec','RecYds','RecTD','Rec1D','RecY/G','Receiving FP','Receiving FPPG']],\\\n",
    "            on = ['Player','G','Tm','Age','Pos'],how = 'outer')\n",
    "    merged_dfs[year-start_year] = merged_dfs[year-start_year].replace(np.nan,0)\n",
    "    \n",
    "    total_dfs.append(pd.read_csv(file_name,header=0))\n",
    "    total_dfs[year-start_year] = passing_dfs[year-start_year][['Player','G','Tm', 'Age','Pos','Cmp','PassAtt','PassYds' ,'PassTD','Int','Sk','Passing FP','Passing FPPG']].merge( \\\n",
    "            merged_dfs[year-start_year][['Player','G','Tm','Age','Pos','Rec','RecYds','RecTD','Rec1D','RecY/G','Receiving FP','Receiving FPPG','RushAtt',\\\n",
    "                      'RushYds','RushTD','Rush1D','Rushing FP', 'Rushing FPPG']],on = ['Player','Tm','Age','Pos'],how = 'outer')\n",
    "    \n",
    "\n",
    "    total_dfs[year-start_year] = total_dfs[year-start_year].replace(np.nan,0)\n",
    "    #Code to recover Team, Pos and Age\n",
    "    total_dfs[year-start_year]['G_x'] = np.where(total_dfs[year-start_year]['G_x'] == 0, total_dfs[year-start_year]['G_y'], total_dfs[year-start_year]['G_x'])\n",
    "    total_dfs[year-start_year] = total_dfs[year-start_year].drop(['G_y'], axis=1)\n",
    "    #total_dfs[year-start_year]['Tm_x'] = np.where(total_dfs[year-start_year]['Tm_x'] == 0, total_dfs[year-start_year]['Tm_y'], total_dfs[year-start_year]['Tm_x'])\n",
    "    #total_dfs[year-start_year] = total_dfs[year-start_year].drop(['Tm_y'], axis=1)\n",
    "    #total_dfs[year-start_year]['Age_x'] = np.where(total_dfs[year-start_year]['Age_x'] == 0, total_dfs[year-start_year]['Age_y'], total_dfs[year-start_year]['Age_x'])\n",
    "    #total_dfs[year-start_year] = total_dfs[year-start_year].drop(['Age_y'], axis=1)\n",
    "    #total_dfs[year-start_year]['Pos_x'] = np.where(total_dfs[year-start_year]['Pos_x'] == 0, total_dfs[year-start_year]['Pos_y'], total_dfs[year-start_year]['Pos_x'])\n",
    "    #total_dfs[year-start_year] = total_dfs[year-start_year].drop(['Pos_y'], axis=1)\n",
    "\n",
    "    total_dfs[year-start_year] = total_dfs[year-start_year].rename(columns={\"G_x\": \"G\",\"Tm_x\":\"Tm\",\"Age_x\":\"Age\",\"Pos_x\":\"Pos\"})\n",
    "    total_dfs[year-start_year]['Season'] = int(year)\n",
    "    \n",
    "    \n",
    "    FP_Total = total_dfs[year-start_year].apply(calcTotalFP,axis=1)\n",
    "    total_dfs[year-start_year]['Total FP'] = FP_Total\n",
    "\n",
    "    total_dfs[year-start_year] = total_dfs[year-start_year][total_dfs[year-start_year].G != 0] #remove erroneous 0 Game entries\n",
    "    FP_Total_PG = total_dfs[year-start_year].apply(calcTotalFP_PG,axis=1)\n",
    "    total_dfs[year-start_year]['Total FPPG'] = FP_Total_PG\n",
    "    total_dfs[year-start_year] = total_dfs[year-start_year].sort_values(by=['Total FP'],ascending=False) #sort by most FPPG\n",
    "\n",
    "    #total_dfs[year-start_year] = total_dfs[year-start_year][['Player','Tm','G','Age','Pos','Passing FP','Passing FPPG','Receiving FP','Receiving FPPG','Rushing FP','Rushing FPPG','Total FP','Total FPPG']]\n",
    "    #total_dfs[year-start_year].set_index('Player',inplace=True)\n",
    "    #total_dfs[year-start_year] = total_dfs[year-start_year][0:275]\n",
    "    total_dfs[year-start_year].index = np.arange(1, len(total_dfs[year-start_year]) + 1)\n",
    "\n",
    "    #append each df to list\n",
    "    QB_dfs.append(pd.read_csv(file_name,header=0))\n",
    "    RB_dfs.append(pd.read_csv(file_name,header=0))\n",
    "    WR_dfs.append(pd.read_csv(file_name,header=0))\n",
    "    TE_dfs.append(pd.read_csv(file_name,header=0))\n",
    "    #FIlter the copied dfs\n",
    "    QB_dfs[year-start_year] = total_dfs[year-start_year].loc[total_dfs[year-start_year]['Pos'].isin(['QB','qb'])] #show QBs\n",
    "    RB_dfs[year-start_year] = total_dfs[year-start_year].loc[total_dfs[year-start_year]['Pos'].isin(['RB','rb'])] #show QBs\n",
    "    WR_dfs[year-start_year] = total_dfs[year-start_year].loc[total_dfs[year-start_year]['Pos'].isin(['WR','wr'])] #show QBs\n",
    "    TE_dfs[year-start_year] = total_dfs[year-start_year].loc[total_dfs[year-start_year]['Pos'].isin(['TE','TE/te','te'])] #show QBs\n",
    "    TE_dfs[year-start_year].index = np.arange(1, len(TE_dfs[year-start_year]) + 1)\n",
    "    QB_dfs[year-start_year].index = np.arange(1, len(QB_dfs[year-start_year]) + 1)\n",
    "    WR_dfs[year-start_year].index = np.arange(1, len(WR_dfs[year-start_year]) + 1)\n",
    "    RB_dfs[year-start_year].index = np.arange(1, len(RB_dfs[year-start_year]) + 1)\n",
    "    #Add to new DF\n",
    "    newDF = newDF.append(total_dfs[year-start_year].loc[total_dfs[year-start_year]['Player'].str.contains(\"Le'Veon Bell\",na=False)],sort=False)\n",
    "newDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What do i want to do: plots for each position  \n",
    "#Fig1 contains positional plots over the years\n",
    "begin_year=2016\n",
    "final_year=2019\n",
    "fig1, ax = plt.subplots(2, 2, sharex='col',sharey=True, figsize=(60, 40))\n",
    "fig2, ax1 = plt.subplots(2, 2, sharex='col',sharey=True,figsize=(60, 40))\n",
    "\n",
    "#fig2, ax2 = plt.subplots((end_year-start_year)+1,1,sharex='col', sharey=True, figsize=(15, 30))\n",
    "\n",
    "plt.rc('font', size=18)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=40)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=40)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=30)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=30)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=26)    # legend fontsize\n",
    "plt.rcParams['axes.grid'] = True\n",
    "\n",
    "#color = ['red','blue','green','black']\n",
    "# Defining custom 'xlim' and 'ylim' values.\n",
    "custom_ylim = (0, 700)\n",
    "# Setting the values for all axes.\n",
    "plt.setp(ax, ylim=custom_ylim)\n",
    "#plt.setp(ax2, ylim=custom_ylim)\n",
    "plt.yticks(np.arange(custom_ylim[0],custom_ylim[1], 50)) \n",
    "plt.xticks(np.arange(1)) \n",
    "\n",
    "\n",
    "for year in range(begin_year,final_year+1): #loop over all years to consider, year is f.e start_year\n",
    "    #Grouping into tiers\n",
    "    thresh_arr = [12, 24, 36, 48]\n",
    "    TE_tier0 = TE_dfs[year-start_year][0:thresh_arr[0]]\n",
    "    TE_tier1 = TE_dfs[year-start_year][thresh_arr[0]:thresh_arr[1]]\n",
    "    TE_tier2 = TE_dfs[year-start_year][thresh_arr[1]:thresh_arr[2]]\n",
    "    TE_tier3 = TE_dfs[year-start_year][thresh_arr[2]:thresh_arr[3]]\n",
    "    TE_tier4 = TE_dfs[year-start_year][thresh_arr[3]:len(TE_dfs)+1]\n",
    "    #QB\n",
    "    QB_tier0 = QB_dfs[year-start_year][0:thresh_arr[0]]\n",
    "    QB_tier1 = QB_dfs[year-start_year][thresh_arr[0]:thresh_arr[1]]\n",
    "    QB_tier2 = QB_dfs[year-start_year][thresh_arr[1]:thresh_arr[2]]\n",
    "    QB_tier3 = QB_dfs[year-start_year][thresh_arr[2]:thresh_arr[3]]\n",
    "    QB_tier4 = QB_dfs[year-start_year][thresh_arr[3]:len(QB_dfs)+1]\n",
    "    #RB\n",
    "    RB_tier0 = RB_dfs[year-start_year][0:thresh_arr[0]]\n",
    "    RB_tier1 = RB_dfs[year-start_year][thresh_arr[0]:thresh_arr[1]]\n",
    "    RB_tier2 = RB_dfs[year-start_year][thresh_arr[1]:thresh_arr[2]]\n",
    "    RB_tier3 = RB_dfs[year-start_year][thresh_arr[2]:thresh_arr[3]]\n",
    "    RB_tier4 = RB_dfs[year-start_year][thresh_arr[3]:len(RB_dfs)+1]\n",
    "    #WR\n",
    "    WR_tier0 = WR_dfs[year-start_year][0:thresh_arr[0]]\n",
    "    WR_tier1 = WR_dfs[year-start_year][thresh_arr[0]:thresh_arr[1]]\n",
    "    WR_tier2 = WR_dfs[year-start_year][thresh_arr[1]:thresh_arr[2]]\n",
    "    WR_tier3 = WR_dfs[year-start_year][thresh_arr[2]:thresh_arr[3]]\n",
    "    WR_tier4 = WR_dfs[year-start_year][thresh_arr[3]:len(WR_dfs)+1]\n",
    "   \n",
    "       #Print Tier stats\n",
    "    #print(\"Tier 0: Top \"+str(thresh_arr[0]))\n",
    "    #print(str(year) + \" :QB Tier 0:\" + str(round(QB_tier0['Total FP'].mean(),2)))\n",
    "    #print(str(year) + \": WR Tier 0: \"+ str(round(WR_tier0['Total FP'].mean(),2)))\n",
    "    #print(str(year) + \": RB Tier 0: \"+ str(round(RB_tier0['Total FP'].mean(),2)))\n",
    "    #print(str(year) + \": TE Tier 0: \"+ str(round(TE_tier0['Total FP'].mean(),2))+\"\\n\")\n",
    "    #Plotting of first fig\n",
    "    ax[0,0].plot(QB_tier0.index,QB_tier0['Total FP'],label=year)\n",
    "    ax[0,1].plot(WR_tier0.index,WR_tier0['Total FP'],label=year)\n",
    "    ax[1,0].plot(RB_tier0.index,RB_tier0['Total FP'],label=year)\n",
    "    ax[1,1].plot(TE_tier0.index,TE_tier0['Total FP'],label=year)\n",
    "    \n",
    "    #Plotting of first fig\n",
    "    ax1[0,0].plot(QB_tier1.index,QB_tier0['Total FP'],label=year)\n",
    "    ax1[0,1].plot(WR_tier1.index,WR_tier0['Total FP'],label=year)\n",
    "    ax1[1,0].plot(RB_tier1.index,RB_tier0['Total FP'],label=year)\n",
    "    ax1[1,1].plot(TE_tier1.index,TE_tier0['Total FP'],label=year)\n",
    "    \n",
    "    #Print Tier1 stats\n",
    "    #print(\"Tier 1: Top \"+str(thresh_arr[0]+1) + \" to \" + str(thresh_arr[1]))\n",
    "    print(str(year) + \" :QB Tier 0: \"+ str(round(QB_tier0['Total FP'].mean(),2))+ \" Next tier below: \" +\\\n",
    "             str(round(QB_tier1['Total FP'].mean(),2)) + \"  \" + str(round(QB_tier2['Total FP'].mean(),2)) + \"  \"+\\\n",
    "             str(round(QB_tier3['Total FP'].mean(),2)))\n",
    "    print(str(year) + \" :WR Tier 0: \"+ str(round(QB_tier0['Total FP'].mean(),2))+ \" Next tier below: \" +\\\n",
    "             str(round(WR_tier1['Total FP'].mean(),2)) + \"  \" + str(round(WR_tier2['Total FP'].mean(),2)) + \"  \"+\\\n",
    "             str(round(WR_tier3['Total FP'].mean(),2)))\n",
    "    print(str(year) + \" :RB Tier 0: \"+ str(round(RB_tier0['Total FP'].mean(),2))+ \" Next tier below: \" +\\\n",
    "             str(round(RB_tier1['Total FP'].mean(),2)) + \"  \" + str(round(RB_tier2['Total FP'].mean(),2)) + \"  \"+\\\n",
    "             str(round(RB_tier3['Total FP'].mean(),2)))\n",
    "    print(str(year) + \" :TE Tier 0: \"+ str(round(TE_tier0['Total FP'].mean(),2))+ \" Next tier below: \" +\\\n",
    "             str(round(TE_tier1['Total FP'].mean(),2)) + \"  \" + str(round(TE_tier2['Total FP'].mean(),2)) + \"  \"+\\\n",
    "             str(round(TE_tier3['Total FP'].mean(),2))+\"\\n\")    \n",
    "\n",
    "    #ax2[year-start_year].scatter(total_dfs[year-start_year].index,total_dfs[year-start_year]['Total FPPG'],\\\n",
    "     #                   c=total_dfs[year-start_year]['Pos'],alpha = 0.4)\n",
    "#Plot fig1 stuff\n",
    "ax[0,0].legend(ncol=int(2),loc='upper right')\n",
    "ax[0,1].legend(ncol=int(2),loc='upper right')\n",
    "ax[1,0].legend(ncol=int(2),loc='upper right')\n",
    "ax[1,1].legend(ncol=int(2),loc='upper right')\n",
    "ax[0,0].set_xlabel('QB finish')\n",
    "ax[0,1].set_xlabel('WR finish')\n",
    "ax[1,0].set_xlabel('RB finish')\n",
    "ax[1,1].set_xlabel('TE finish')\n",
    "#Plot fig2 stuff\n",
    "ax1[0,0].legend(ncol=int(2),loc='upper right')\n",
    "ax1[0,1].legend(ncol=int(2),loc='upper right')\n",
    "ax1[1,0].legend(ncol=int(2),loc='upper right')\n",
    "ax1[1,1].legend(ncol=int(2),loc='upper right')\n",
    "ax1[0,0].set_xlabel('QB finish')\n",
    "ax1[0,1].set_xlabel('WR finish')\n",
    "ax1[1,0].set_xlabel('RB finish')\n",
    "ax1[1,1].set_xlabel('TE finish')\n",
    "fig1.suptitle('Tier 0 Fantasy Points for each positional finish', fontsize=26)\n",
    "fig1.show()\n",
    "fig1.savefig('Tier0.png')\n",
    "#Plot fig 2 stuff\n",
    "fig2.suptitle('Tier 1 Fantasy Points for each positional finish', fontsize=26)\n",
    "fig2.show()\n",
    "fig2.savefig('Tier1.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total_dfs[17][0:50]['Pos'].value_counts().to_dict() #output pos\n",
    "#total_dfs[17].loc[total_dfs[17]['Pos'].str.contains('rb',case=False), 'Pos'] = 'RB'\n",
    "#total_dfs[0][0:50]\n",
    "#RB_dfs[19][0:20]\n",
    "#QB_tier\n",
    "\n",
    "total_dfs[17][total_dfs[17]['Player'].str.contains(\"Hooper\",na=False)]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
